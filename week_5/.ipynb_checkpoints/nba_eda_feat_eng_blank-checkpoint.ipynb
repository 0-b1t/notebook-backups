{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Data Analysis\n",
    "\n",
    "The data used in this notebook was downloaded from [Kaggle](https://www.kaggle.com/drgilermo/nba-players-stats#Seasons_Stats.csv).  The original source of the data is [Basketball-reference](http://www.basketball-reference.com/).\n",
    "\n",
    "\n",
    "## General Intro EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tm</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>TS%</th>\n",
       "      <th>3PAr</th>\n",
       "      <th>...</th>\n",
       "      <th>FT%</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1950.0</th>\n",
       "      <td>Curly Armstrong</td>\n",
       "      <td>G-F</td>\n",
       "      <td>31.0</td>\n",
       "      <td>FTW</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217.0</td>\n",
       "      <td>458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950.0</th>\n",
       "      <td>Cliff Barker</td>\n",
       "      <td>SG</td>\n",
       "      <td>29.0</td>\n",
       "      <td>INO</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950.0</th>\n",
       "      <td>Leo Barnhorst</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>CHS</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>192.0</td>\n",
       "      <td>438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950.0</th>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>TOT</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950.0</th>\n",
       "      <td>Ed Bartels</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DNN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player  Pos   Age   Tm     G  GS  MP  PER    TS%  3PAr  ...  \\\n",
       "Year                                                                     ...   \n",
       "1950.0  Curly Armstrong  G-F  31.0  FTW  63.0 NaN NaN  NaN  0.368   NaN  ...   \n",
       "1950.0     Cliff Barker   SG  29.0  INO  49.0 NaN NaN  NaN  0.435   NaN  ...   \n",
       "1950.0    Leo Barnhorst   SF  25.0  CHS  67.0 NaN NaN  NaN  0.394   NaN  ...   \n",
       "1950.0       Ed Bartels    F  24.0  TOT  15.0 NaN NaN  NaN  0.312   NaN  ...   \n",
       "1950.0       Ed Bartels    F  24.0  DNN  13.0 NaN NaN  NaN  0.308   NaN  ...   \n",
       "\n",
       "          FT%  ORB  DRB  TRB    AST  STL  BLK  TOV     PF    PTS  \n",
       "Year                                                              \n",
       "1950.0  0.705  NaN  NaN  NaN  176.0  NaN  NaN  NaN  217.0  458.0  \n",
       "1950.0  0.708  NaN  NaN  NaN  109.0  NaN  NaN  NaN   99.0  279.0  \n",
       "1950.0  0.698  NaN  NaN  NaN  140.0  NaN  NaN  NaN  192.0  438.0  \n",
       "1950.0  0.559  NaN  NaN  NaN   20.0  NaN  NaN  NaN   29.0   63.0  \n",
       "1950.0  0.548  NaN  NaN  NaN   20.0  NaN  NaN  NaN   27.0   59.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\n\\nfrom scipy import stats\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n\\ndata_url = \\\"https://docs.google.com/spreadsheets/d/1m0jaYL1KGjxW1cKJUQxVTcPOnm7v7NZEBKRZADCmc68/export?format=csv\\\"\\nnba = pd.read_csv(data_url, index_col=0)\\nnba.head()\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\n\\nfrom scipy import stats\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\\n\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\\n\\ndata_url = \\\"https://docs.google.com/spreadsheets/d/1m0jaYL1KGjxW1cKJUQxVTcPOnm7v7NZEBKRZADCmc68/export?format=csv\\\"\\nnba = pd.read_csv(data_url, index_col=0)\\nnba.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_url = \"https://docs.google.com/spreadsheets/d/1m0jaYL1KGjxW1cKJUQxVTcPOnm7v7NZEBKRZADCmc68/export?format=csv\"\n",
    "nba = pd.read_csv(data_url, index_col=0)\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = nba.drop(columns=[\"blank2\", \"blanl\"])\n",
    "nba = nba.dropna(subset=[\"Year\", \"Player\", \"Pos\", \"Tm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We have a lot of useful data here, but most predictive models that we'll be looking at only like numeric data.  To still use our information we have to do a little bit of reformatting.\n",
    "\n",
    "### One Hot Encoding / Dummy Encoding\n",
    "\n",
    "For example, for team, we might \"one-hot encode\" (aka create dummy variables).  This is a way of creating a series of variables indicating True/False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe that is a subset of the `nba` dataframe.  Only include in this subset:\n",
    "\n",
    "* Columns: `PTS`, `Player`, & `Tm`\n",
    "* Rows: a random selection of 15 rows (use 42 as the `random_state`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# subset columns\n",
    "nba_sub = ____\n",
    "\n",
    "# subset rows\n",
    "nba_sub = ____\n",
    "\n",
    "nba_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pd.get_dummies()` on the subset.\n",
    "\n",
    "* What happened?\n",
    "* What might we change about this and why?\n",
    "* What does the `drop_first` argument of `pd.get_dummies()` do and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideOutput": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some issues that come up with using `pd.get_dummies` in a machine learning workflow.  For today, we'll stick with it due to its ease of use compared to more powerful options.\n",
    "\n",
    "Using [`sklearn.preprocessing.OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) overcomes the issues that `pd.get_dummies` can run into, but it has a little more complex usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary column named `is_old` that shows whether or not the `Year` variable is before 1980."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary column named `is_california` that shows whether or not a team is located in california."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_teams = [\"LAL\", \"LAC\", \"GSW\", \"SAC\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make up some data to be ordinal encoded.\n",
    "\n",
    "* Using the `grades` list create a sample of 20 random letters\n",
    "* Create a 1 column DataFrame from this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "grades = [\"A\", \"B\", \"C\", 'D', 'F']\n",
    "rand_grades = ____\n",
    "\n",
    "grade_df = ____\n",
    "grade_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable that is an ordinal encoding of grade.  Have `A` be 1 and `F` be 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "\n",
    "Some methods we'll see are sensitive to our variables being on different scales.  For example, if you have variables for a person's height and their annual income, the height feature will have a much much smaller value than the income feature.  In some methods, this will lead to the income variable being a louder signal than the height variable.  Larger magnitude variables can end up drowning out smaller magnitude ones, and this can be an issue if we think height will be an important predictor.\n",
    "\n",
    "To address this issue, we can scale the variables to have equal footing.  This won't change the shape of their distribution.  Not changing shape means that the patterns within and between the variable aren't lost by scaling, the patterns are preserved, the values have just been standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a subset of the nba dataset that has the columns `PTS` and `Age`.\n",
    "* Drop all NAs\n",
    "* Use the pandas boxplot method on this resulting data.\n",
    "* Plot these variables on a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to split into groups to evaluate 2 different scalers.  The below code will decide the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "data_scientists = ['Anthony', 'Dillan', 'Gaukhar', 'Harinder', 'James',\n",
    "                   'Josh', 'Leon', 'Mason', 'Rachel', 'Steve']\n",
    "# fmt: on\n",
    "\n",
    "# Randomize order\n",
    "np.random.shuffle(data_scientists)\n",
    "\n",
    "n = len(data_scientists) // 2\n",
    "print(f\"Use StandardScaler: {data_scientists[:n]}\")\n",
    "print(f\"Use MinMaxScaler: {data_scientists[n:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick your poison (comment out the one that your group isn't doing)\n",
    "scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use a scaler to scale the `PTS` and `Age` data.\n",
    "* The output of the scaler is a numpy array, convert this back to a dataframe\n",
    "* Recreate the same box plots from before.\n",
    "  * What's the same?\n",
    "  * What's different?\n",
    "  * What's the minimum value of the numeric axis? the max value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "# .fit() methods 'learn' something from your data\n",
    "# They don't apply any of these learnings\n",
    "# In the case of a scaler we have to call .transform\n",
    "# Alternatively, we could use .fit_transform() to do \n",
    "# both of these things in one step\n",
    "scaler.fit(____)\n",
    "\n",
    "scaled = scaler.transform(____)\n",
    "\n",
    "scaled_df = ____\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bonus: what attributes does your scaler have? What is the significance of these?\n",
    "* Bonus Bonus: can you recreate this same scaling from scratch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
