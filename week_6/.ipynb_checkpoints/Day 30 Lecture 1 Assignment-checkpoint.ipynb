{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DPEH2GvdWEc"
   },
   "source": [
    "## Day 30 Lecture 1 Assignment\n",
    "\n",
    "In this assignment, we will build our first random forest model. We will use a dataset containing churn information for a telephone company's customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yx3zL4jfdWEc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# !pip install category_encoders\n",
    "from category_encoders import LeaveOneOutEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2vkGnLGKV9X"
   },
   "source": [
    "Read in the telecom churn dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/Thinkful-Ed/data-science-lectures/master/telecom_churn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NO2s06udWEg"
   },
   "outputs": [],
   "source": [
    "# answer here\n",
    "data_url='https://raw.githubusercontent.com/Thinkful-Ed/data-science-lectures/master/telecom_churn.csv'\n",
    "\n",
    "df = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Do4wf0HedWEi"
   },
   "source": [
    "Perform the following preprocessing steps:\n",
    "\n",
    "- This dataset has many columns; identify a subset of 10-15 features that you think could affect a customer's propensity to churn (also called \"customer loss\" or \"customer attrition\"). Include at least 1 categorical variable.\n",
    "- Drop all rows that containing any missing values (this should be a fairly small number of rows)\n",
    "- Convert the response from a string to a binary 1-0 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOYothvxdWEi"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9or_wHIEdWEk"
   },
   "source": [
    "Although some implementations of tree-based models support categorical variables directly, scikit-learn's implementation does not, so we will need to convert our categorical variable(s) into numbers. In linear regression, we used one-hot/dummy encoding, but this has drawbacks that can be particularly problematic in the context of trees. Namely, dummy encoding can lead to very sparse columns when dealing with high-dimensional categorical features; the tree treats these levels as indepedent features is very unlikely to make a split on any of the individual levels, since the corresponding columns consist almost entirely consist of a single value.\n",
    "\n",
    "Ideally, we would consider all of the levels simultaneously, which trees can do efficiently. However, sklearn does not implement this efficient algorithm for splitting on categorical variables. In this situation, a better alternative to dummy encoding is leave-one-out-encoding. This transforms each categorical into its conditional probability of the positive class, excluding the observation itself to avoid potential data leakage. Perform the following steps:\n",
    "\n",
    "- Create an 80-20 train/test split on the data\n",
    "- Fit a leave-one-out encoder to the training data and encode the categorical variables in the training data. The category_encoders package is helpful for this task. (Note that this ordering is important; if we fitted the encoder to the full dataset before making the train/test split, we would introduce data leakage by allowing the test data to affecting the estimates of the category-conditional probabilities.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSzcnmlHdWEl"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4_2MdfddWEo"
   },
   "source": [
    "Next, fit the random forest model. You can tinker with or tune the parameters if you like, although we will use the default parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLpHIpL1dWEp"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClKz91ajdWEq"
   },
   "source": [
    "To evaluate our model, produce the predicted values for the test sample. Remember to apply our previously fitted encoder to the test data prior to making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9tiXUV2dWEr"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4QYFoevdWEs"
   },
   "source": [
    "After making the predictions, print out the classification report (sklearn.metrics.classification_report). In addition, plot the confusion matrix and ROC curve. How did our model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmzoxEQsdWEs"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_CEPHhIwdWEu"
   },
   "source": [
    "Print the feature importances, ordered by importance from high to low. What is the default sklearn feature importance metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W1b3f-i-dWEv"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 30 Lecture 1 Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
