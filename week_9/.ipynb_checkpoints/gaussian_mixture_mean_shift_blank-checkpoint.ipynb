{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qqhx94S6rxlf"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\n\\nfrom tqdm.notebook import tqdm\\n\\nfrom scipy import stats\\n\\nfrom sklearn.mixture import GaussianMixture\\nfrom sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\\n\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\\n\\nimport plotly.express as px\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\n\\nfrom tqdm.notebook import tqdm\\n\\nfrom scipy import stats\\n\\nfrom sklearn.mixture import GaussianMixture\\nfrom sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\\n\\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\\n\\nimport plotly.express as px\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Store Number</th>\n",
       "      <th>Store Name</th>\n",
       "      <th>Ownership Type</th>\n",
       "      <th>Street Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State/Province</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22859</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>3509-142865</td>\n",
       "      <td>TYS Foodcourt (Knoxville)</td>\n",
       "      <td>Licensed</td>\n",
       "      <td>2055 Airport Hwy</td>\n",
       "      <td>Alcoa</td>\n",
       "      <td>TN</td>\n",
       "      <td>US</td>\n",
       "      <td>377013316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GMT-05:00 America/New_York</td>\n",
       "      <td>-83.99</td>\n",
       "      <td>35.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22860</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>11293-104144</td>\n",
       "      <td>Cusick &amp; Alcoa</td>\n",
       "      <td>Company Owned</td>\n",
       "      <td>121 Cusick Rd</td>\n",
       "      <td>Alcoa</td>\n",
       "      <td>TN</td>\n",
       "      <td>US</td>\n",
       "      <td>377013125</td>\n",
       "      <td>865-982-0642</td>\n",
       "      <td>GMT-05:00 America/New_York</td>\n",
       "      <td>-83.98</td>\n",
       "      <td>35.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22895</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>18984-190185</td>\n",
       "      <td>Ingles Farragut # 91</td>\n",
       "      <td>Licensed</td>\n",
       "      <td>11817 Kingston Pike</td>\n",
       "      <td>Farragut</td>\n",
       "      <td>TN</td>\n",
       "      <td>US</td>\n",
       "      <td>37934</td>\n",
       "      <td>865-777-4360</td>\n",
       "      <td>GMT-05:00 America/New_York</td>\n",
       "      <td>-84.12</td>\n",
       "      <td>35.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand  Store Number                 Store Name Ownership Type  \\\n",
       "22859  Starbucks   3509-142865  TYS Foodcourt (Knoxville)       Licensed   \n",
       "22860  Starbucks  11293-104144             Cusick & Alcoa  Company Owned   \n",
       "22895  Starbucks  18984-190185       Ingles Farragut # 91       Licensed   \n",
       "\n",
       "            Street Address      City State/Province Country   Postcode  \\\n",
       "22859     2055 Airport Hwy     Alcoa             TN      US  377013316   \n",
       "22860        121 Cusick Rd     Alcoa             TN      US  377013125   \n",
       "22895  11817 Kingston Pike  Farragut             TN      US      37934   \n",
       "\n",
       "       Phone Number                    Timezone  Longitude  Latitude  \n",
       "22859           NaN  GMT-05:00 America/New_York     -83.99     35.81  \n",
       "22860  865-982-0642  GMT-05:00 America/New_York     -83.98     35.81  \n",
       "22895  865-777-4360  GMT-05:00 America/New_York     -84.12     35.90  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"lat_min = 35.71\\nlat_max = 36.55\\nlon_min = -84.55\\nlon_max = -82.37\\n\\n# Potential extra practice:\\n#  * plot all the starbs locations in one color\\n#  * plot my location in a different color\\nadam_lat = 36.3\\nadam_lon = -82.4\\n\\ndata_url = \\\"https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/Data%20Sets%20Clustering/starbucks_locations.csv\\\"\\nstarbs = pd.read_csv(data_url)\\n\\nstarbs = starbs[starbs[\\\"Latitude\\\"].between(lat_min, lat_max)]\\nstarbs = starbs[starbs[\\\"Longitude\\\"].between(lon_min, lon_max)]\\nstarbs.head(3)\";\n",
       "                var nbb_formatted_code = \"lat_min = 35.71\\nlat_max = 36.55\\nlon_min = -84.55\\nlon_max = -82.37\\n\\n# Potential extra practice:\\n#  * plot all the starbs locations in one color\\n#  * plot my location in a different color\\nadam_lat = 36.3\\nadam_lon = -82.4\\n\\ndata_url = \\\"https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/Data%20Sets%20Clustering/starbucks_locations.csv\\\"\\nstarbs = pd.read_csv(data_url)\\n\\nstarbs = starbs[starbs[\\\"Latitude\\\"].between(lat_min, lat_max)]\\nstarbs = starbs[starbs[\\\"Longitude\\\"].between(lon_min, lon_max)]\\nstarbs.head(3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat_min = 35.71\n",
    "lat_max = 36.55\n",
    "lon_min = -84.55\n",
    "lon_max = -82.37\n",
    "\n",
    "# Potential extra practice:\n",
    "#  * plot all the starbs locations in one color\n",
    "#  * plot my location in a different color\n",
    "adam_lat = 36.3\n",
    "adam_lon = -82.4\n",
    "\n",
    "data_url = \"https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/Data%20Sets%20Clustering/starbucks_locations.csv\"\n",
    "starbs = pd.read_csv(data_url)\n",
    "\n",
    "starbs = starbs[starbs[\"Latitude\"].between(lat_min, lat_max)]\n",
    "starbs = starbs[starbs[\"Longitude\"].between(lon_min, lon_max)]\n",
    "starbs.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 Warm up 🔥\n",
    "\n",
    "According to the distribution of our filtered data in the `starbs` dataframe.\n",
    "\n",
    "We're most likely to find a starbucks at which of these values of `'Longitude'`?\n",
    "* (A) -81\n",
    "* (B) -83\n",
    "* (C) -84\n",
    "* (D) -85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2af0ab392c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"starbs[\\\"Longitude\\\"].hist(bins=30)\";\n",
       "                var nbb_formatted_code = \"starbs[\\\"Longitude\\\"].hist(bins=30)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "starbs[\"Longitude\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the distribution of our filtered data in the `starbs` dataframe.\n",
    "\n",
    "We're most likely to find a starbucks at which of these values of `'Latitude'`?\n",
    "* (A) 35\n",
    "* (B) 36\n",
    "* (C) 37\n",
    "* (D) 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PzkRHuE9z25r"
   },
   "source": [
    "## Gaussian mixture\n",
    "\n",
    "### MLE\n",
    "\n",
    "We're given the below data, and we're told that the data is measurements of some snail characteristic 🐌.  We want to try and figure out what the *population* distribution looks like.  Remember we just have a *sample*, but the population is all of the snail species we're studying.  Having a good estimate of this population distribution can benefit and guide our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "data = [ 8.521, 16.586, 11.154,  3.323, 13.662, 14.649,  6.149,  5.528,\n",
    "        18.871, 11.498,  8.921,  5.776,  7.292,  6.638, 13.321,  7.073,\n",
    "         8.827, 10.375,  1.645, 13.566, 19.846,  6.347,  8.617, 14.462,\n",
    "         4.483, 11.170, 11.322,  5.710, 11.311,  7.672,  9.765, 14.443,\n",
    "        18.360,  9.304, 10.247, 10.955, 14.194,  8.344,  5.783, 12.533,\n",
    "        12.937,  0.846,  4.925,  9.006, 11.443, 16.160, 10.751,  8.513,\n",
    "        23.865, 17.228]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Before plotting:\n",
    "    * What kind of distribution do you expect this type of data to follow?\n",
    "    * What 'parameters' does that distribution have?\n",
    "        * i.e. these are what you'd need to give `np.random.<distribution_name>()` so it can know what shape of distribution you want random numbers from\n",
    "\n",
    "\n",
    "* Now let's plot a histogram.  Does the shape of the data's distribution support your hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we're after the population distribution.\n",
    "\n",
    "* Re-plot the histogram\n",
    "* Add a vertical line at 20 (color it and give it a label for the legend)\n",
    "* Add a vertical line at 10 (color it and give it a label for the legend)\n",
    "* Add a vertical line at  5 (color it and give it a label for the legend)\n",
    "\n",
    "Let's say these are 3 guesses at what the population mean are.  Given our data, which of these is the most *likely*.  Due to the nature of random sampling, it's possible that all 3 of these are valid, but we it's not practical to assume that we got a very unusual random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're engaging in a process called Maximum Likelihood Estimation (MLE).  We're trying to Estimate the population mean based on what's most Likely.  We want our Estimate to have the Maximum Likelihood of being correct.\n",
    "\n",
    "Below is a visualization of us trying to find the population mean via MLE.\n",
    "\n",
    "Note, this is why the mean parameter of `np.random.normal` is called `loc`.\n",
    "\n",
    "<img src='images/mean_mle.gif' width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one more parameter we'd need to esimate in order to fully describe our distribution's shape.  This is why this parameter in `np.random.normal` is called `scale` (we scale the width, the height is derived from the width).\n",
    "\n",
    "<img src='images/std_mle.gif' width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the maximum likelihood estimates for the population mean and standard deviation are the equal to the sample mean and sample standard deviations.\n",
    "\n",
    "* Generate 1000 random data points from our estimate popuation distribution\n",
    "* Plot this resulting distribution, compare it to our sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixing\n",
    "\n",
    "We just got some new data.  This data was collected from 2 separate species of snails 🐌.\n",
    "\n",
    "We know these snails each follow a normal distribution, and we know that they have different means & standard deviations.  Unfortunately, the scientist in the field didn't write down which species each observation is, so we have to try and figure out these 2 separate distributions from a sample of mixed data.\n",
    "\n",
    "If we knew the species labels, we could perform the same MLE process we did above (filter and perform MLE 1 at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "data = [11.83984961, 12.37143473, 26.15417807, 28.58500880, 27.70571253,\n",
    "        24.24028217, 18.33611103, 15.28117383, 14.57235710, 18.49006327,\n",
    "        37.83761751, 18.82148403, 36.62430095, 26.61444903, 15.3433858 ,\n",
    "        24.60865873, 31.67437436, 26.08487739, 14.75279305, 25.63485726,\n",
    "        30.44683604, 29.64163292, 14.91536797, 20.48912193, 27.97187397,\n",
    "        11.41235662, 17.90399557, 33.82514212, 17.71352474, 25.98954934,\n",
    "        19.86878159, 26.92304096, 16.25738730, 29.10667734, 31.06548273,\n",
    "        21.14768063, 29.93913722, 25.32381510, 18.98788655, 16.60772929,\n",
    "        25.00896332, 17.41901911, 14.21902871, 27.90108363, 26.99118323,\n",
    "        26.03784060, 31.83483958, 25.73633429, 31.48278996, 24.23683382,\n",
    "        19.24019041, 14.73365444, 27.70687662, 19.82397780, 14.58054905,\n",
    "        22.51116415, 21.31616800, 26.34025573, 28.45094146, 24.61646750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of the data.  Do you think we'll be able to separate out 2 normal distributions from it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure this out, we'll throw in some initial guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_guess(\n",
    "    data, x1_mean, x1_std, x2_mean, x2_std, n=int(1e6), prob_1=None, prob_2=None\n",
    "):\n",
    "    \"\"\"Helper function for plotting GMM process\"\"\"\n",
    "    sns.distplot(np.random.normal(x1_mean, x1_std, n), hist=False)\n",
    "    sns.distplot(np.random.normal(x2_mean, x1_std, n), hist=False)\n",
    "\n",
    "    if prob_1 is not None and prob_2 is not None:\n",
    "        prob_1 = MinMaxScaler().fit_transform(prob_1)\n",
    "        prob_2 = MinMaxScaler().fit_transform(prob_2)\n",
    "\n",
    "        for x, p1, p2 in zip(data, prob_1, prob_2):\n",
    "            if p1 > p2:\n",
    "                c = \"blue\"\n",
    "                alpha = p1[0]\n",
    "            else:\n",
    "                c = \"orange\"\n",
    "                alpha = p2[0]\n",
    "\n",
    "            plt.scatter(x, 0, alpha=alpha * 0.8, c=c)\n",
    "    else:\n",
    "        plt.scatter(data, [0 for _ in data], c=\"black\")\n",
    "\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_guess(data, x1_mean=30, x1_std=6, x2_mean=10, x2_std=6)\n",
    "plt.title(\"initial guess\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to these distributions, we can now assign a probability (or likelihood) that each point came from each distribution.  Using this, we can split the data into 2 groups:\n",
    "\n",
    "* (1) points more likely to have come from the orange distribution\n",
    "* (2) points more likely to have come from the blue distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\"mixture\"])\n",
    "df[\"prob_blue\"] = stats.norm(30, 6).pdf(df[\"mixture\"])\n",
    "df[\"prob_orange\"] = stats.norm(10, 6).pdf(df[\"mixture\"])\n",
    "df[\"label\"] = \"blue\"\n",
    "df.loc[df[\"prob_orange\"] > df[\"prob_blue\"], \"label\"] = \"orange\"\n",
    "\n",
    "plot_guess(\n",
    "    data,\n",
    "    x1_mean=30,\n",
    "    x1_std=6,\n",
    "    x2_mean=10,\n",
    "    x2_std=6,\n",
    "    prob_1=df[[\"prob_blue\"]],\n",
    "    prob_2=df[[\"prob_orange\"]],\n",
    ")\n",
    "plt.title(\"initial guess\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 2 individual groups of data! And just like in the single species example, we can now make a better guess about what each distribution looks like.  We can use this to update our guess of the distribution shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"label\").agg({\"mixture\": [\"mean\", \"std\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_guess(\n",
    "    data,\n",
    "    x1_mean=27.508272,\n",
    "    x1_std=3.867000,\n",
    "    x2_mean=16.238787,\n",
    "    x2_std=2.525888,\n",
    "    prob_1=df[[\"prob_blue\"]],\n",
    "    prob_2=df[[\"prob_orange\"]],\n",
    ")\n",
    "plt.title(\"updated guess\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And repeat! This process we just went through goes by the name Gussian Mixture Modeling.  Gaussian is another name for the normal distribution (named after a dude who contributed a lot to math and statistics).\n",
    "\n",
    "Let's see how we can approach this problem with sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = ____\n",
    "gmm.fit(df[[\"mixture\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the means and standard deviations that sklearn settled on after going through that process a couple more iterations.  Note that in this simple case, our 1 iteration algorithm got pretty similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_mean, x2_mean = gmm.means_\n",
    "x1_std, x2_std = np.sqrt(gmm.covariances_)\n",
    "\n",
    "x1_mean = x1_mean[0]\n",
    "x2_mean = x2_mean[0]\n",
    "x1_std = x1_std[0][0]\n",
    "x2_std = x2_std[0][0]\n",
    "\n",
    "print(f\"Cluster 1 - mean: {x1_mean:.2f}; std: {x1_std:.2f}\")\n",
    "print(f\"Cluster 2 - mean: {x2_mean:.2f}; std: {x2_std:.2f}\")\n",
    "\n",
    "plot_guess(\n",
    "    data,\n",
    "    x1_mean=x1_mean,\n",
    "    x1_std=x1_std,\n",
    "    x2_mean=x2_mean,\n",
    "    x2_std=x2_std,\n",
    "    prob_1=df[[\"prob_blue\"]],\n",
    "    prob_2=df[[\"prob_orange\"]],\n",
    ")\n",
    "plt.title(\"sklearn's guess\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's cool and all, but our data almost never has just a single column (i.e. this example was *univariate*).  Let's look at a case with multiple variables (i.e. *multivariate*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon = starbs[[\"Latitude\", \"Longitude\"]].copy()\n",
    "\n",
    "fig = px.scatter_geo(lat_lon, \"Latitude\", \"Longitude\", scope=\"usa\")\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like KMeans, we need to decide up front how many clusters we want the clustering process to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAu-thrM0ICo"
   },
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create and fit a `GaussianMixture()` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare `GaussianMixture()` to `KMeans()`.\n",
    "\n",
    "* Create and fit a `KMeans()` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print the resulting centroids from each method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results visualized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the `GaussianMixture.predict_proba()` method.\n",
    "* What are the top 3 observations we are least confident about?\n",
    "* What are the top 3 observations we are most confident about?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6HjnWGrFO-q",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the results comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3521,
     "status": "ok",
     "timestamp": 1580406740855,
     "user": {
      "displayName": "Adam Spannbauer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU2JSQZkFVVbFv_OhPGdmiwr3ChGbq34PCZXJz=s64",
      "userId": "04097551985177324740"
     },
     "user_tz": 300
    },
    "id": "bvauiLwZ0m3v",
    "outputId": "198c2f33-e1af-4aae-a43c-cc4f9bb75ae0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_df = lat_lon.copy()\n",
    "plot_df[\"label\"] = gauss.predict(lat_lon)\n",
    "plot_df = plot_df.sort_values(\"label\")\n",
    "\n",
    "centers_df = pd.DataFrame(gauss.means_, columns=[\"Latitude\", \"Longitude\"])\n",
    "centers_df[\"label\"] = \"Cluster center\"\n",
    "\n",
    "plot_df = pd.concat((plot_df, centers_df), sort=False)\n",
    "\n",
    "fig = px.scatter_geo(\n",
    "    plot_df,\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    color=\"label\",\n",
    "    scope=\"usa\",\n",
    "    title=\"Gaussian Mixture Model Results\",\n",
    "    hover_name=plot_df.index,\n",
    ")\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "plot_df = lat_lon.copy()\n",
    "plot_df[\"label\"] = kmeans.labels_\n",
    "plot_df = plot_df.sort_values(\"label\")\n",
    "\n",
    "centers_df = pd.DataFrame(kmeans.cluster_centers_, columns=[\"Latitude\", \"Longitude\"])\n",
    "centers_df[\"label\"] = \"Cluster center\"\n",
    "\n",
    "plot_df = pd.concat((plot_df, centers_df), sort=False)\n",
    "\n",
    "fig = px.scatter_geo(\n",
    "    plot_df,\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    color=\"label\",\n",
    "    scope=\"usa\",\n",
    "    title=\"KMeans Results\",\n",
    "    hover_name=plot_df.index,\n",
    ")\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVwJByXZztt_"
   },
   "source": [
    "## Mean-shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `matplotlib` to plot the East TN Starbucks\n",
    "* Label the `x` and `y` axes\n",
    "* Give the plot a title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1662,
     "status": "ok",
     "timestamp": 1580406766461,
     "user": {
      "displayName": "Adam Spannbauer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU2JSQZkFVVbFv_OhPGdmiwr3ChGbq34PCZXJz=s64",
      "userId": "04097551985177324740"
     },
     "user_tz": 300
    },
    "id": "EnPvZhaqih5R",
    "outputId": "26bdc4a0-d4d3-474d-84ce-b2b49cabad23"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `sns.kdeplot()` to show the distribution of Latitude and Longitude separately.\n",
    "* How many clusters do you expect to find if clustering only on one of these variables?\n",
    "* Play with the `bw` parameter of `sns.kdeplot()`.  How does this change how many clusters you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "sns.kdeplot(____, ax=axes[0])\n",
    "sns.kdeplot(____, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `sns.kdeplot()` to show the 2d distribution of Latitude and Longitude.\n",
    "* Add the starbucks locations to the plot.\n",
    "* How many clusters do you expect to find if clustering only on one of these variables?\n",
    "* Play with the `bw` parameter of `sns.kdeplot()`.  How does this change how many clusters you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3482,
     "status": "ok",
     "timestamp": 1580408343569,
     "user": {
      "displayName": "Adam Spannbauer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU2JSQZkFVVbFv_OhPGdmiwr3ChGbq34PCZXJz=s64",
      "userId": "04097551985177324740"
     },
     "user_tz": 300
    },
    "id": "IAAWE0zNybug",
    "outputId": "ca5ccd31-de13-4d9c-fd2f-74cf59c04bb2"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(____)\n",
    "plt.scatter(____)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `MeanShift()` to cluster the observations\n",
    "* The default `bandwidth` used by `MeanShift()` is calculated using `sklearn.cluster.estimate_bandwidth()` (shown below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_bw = estimate_bandwidth(lat_lon)\n",
    "print(f\"Default bandwidth: {default_bw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1642,
     "status": "ok",
     "timestamp": 1580409516160,
     "user": {
      "displayName": "Adam Spannbauer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAU2JSQZkFVVbFv_OhPGdmiwr3ChGbq34PCZXJz=s64",
      "userId": "04097551985177324740"
     },
     "user_tz": 300
    },
    "id": "BLxIF9rXq_l-",
    "outputId": "cfee4236-01d0-45ec-f6d3-7e828a96237f"
   },
   "outputs": [],
   "source": [
    "# Define a variable to hold the selected bw for use in plotting later\n",
    "bw = _____\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the resulting cluster centers.  How many clusters were found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Redo the above plot colored by cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn converts all columns that look like numbers to numeric\n",
    "# we dont want a color bar to represent cluster labels as they're purely\n",
    "# categorical. to stop seaborn from thinking of our labels as continuous\n",
    "# we're adding cluster labels as strings and adding an underscore\n",
    "\n",
    "lat_lon[\"label\"] = mean_shift.labels_.astype(str)\n",
    "lat_lon[\"label\"] += \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(____)\n",
    "sns.scatterplot(____)\n",
    "\n",
    "plt.title(\"Clustered East TN Starbucks\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra practice in case we have time:\n",
    "\n",
    "* The nba dataset is loaded & cleaned for you below.\n",
    "* Apply mean shift and interpret the clusters.\n",
    "* Based on your interpretation, are these good clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/Data%20Sets%20Clustering/nba_player_seasons.csv\"\n",
    "nba = pd.read_csv(data_url)\n",
    "\n",
    "nba = nba[(nba[\"GS\"] >= 20) & (nba[\"MP\"] >= 10)]\n",
    "nba = nba.dropna().reset_index(drop=True)\n",
    "nba_og = nba.copy()\n",
    "\n",
    "nba = nba[[\"PTS\", \"TRB\", \"TOV\", \"AST\", \"BLK\", \"Age\"]]\n",
    "nba.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpaRDTSwWwvP5Lgs+zXRY7",
   "collapsed_sections": [],
   "name": "starbucks_gaussian_mixture_mean_shift.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
