{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "*(clicking links should jump to sections if working in jupyter)*\n",
    "\n",
    "* [Imports](#Imports)\n",
    "  * Self-explanatory\n",
    "* [Helper functions](#Helper-functions)\n",
    "  * You can skip this section unless you're curious.  The contents of these functions are outside the scope of what we care about today.\n",
    "* [Off to the races](#Off-to-the-races)\n",
    "  * A warm up to discuss the intuition of the ideas behind t-tests and hypothesis testing\n",
    "* [t-test math](#t-test-math)\n",
    "  * Walking through the formula, hypotheses, and p-value\n",
    "* [Performing t-tests in python](#Performing-t-tests-in-python)\n",
    "  * Self-explanatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c27f704bde96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# For (relatively) easy animated plots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# !pip install plotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\n\\n# For performing t-test\\nfrom scipy import stats\\n\\n# For (relatively) easy animated plots\\n# !pip install plotly\\nimport plotly.graph_objects as go\\nimport plotly.express as px\\n\\n# For typical plotting\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\n\\n# For performing t-test\\nfrom scipy import stats\\n\\n# For (relatively) easy animated plots\\n# !pip install plotly\\nimport plotly.graph_objects as go\\nimport plotly.express as px\\n\\n# For typical plotting\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\n%matplotlib inline\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For performing t-test\n",
    "from scipy import stats\n",
    "\n",
    "# For (relatively) easy animated plots\n",
    "# !pip install plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# For typical plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for generating race data\n",
    "def _gen_player_data(color, name=\"\", y=0, n_steps=20):\n",
    "    \"\"\"Generate a random race time and split it out over time steps for plotting\"\"\"\n",
    "    s = 0.3\n",
    "    if color == \"#4C78A8\":\n",
    "        s = 4.0\n",
    "\n",
    "    # Generate random race times\n",
    "    finish_time = np.random.normal(n_steps * 0.8, s)\n",
    "\n",
    "    # Find x position for each frame of race\n",
    "    rate = 1 / finish_time\n",
    "    step = finish_time / n_steps\n",
    "    time_steps = np.arange(n_steps + 1)\n",
    "    x_pos = time_steps * rate\n",
    "\n",
    "    # Store all plotting info for plotly\n",
    "    race_df = pd.DataFrame(\n",
    "        {\n",
    "            \"time\": time_steps,\n",
    "            \"x\": x_pos,\n",
    "            \"y\": y,\n",
    "            \"color\": color,\n",
    "            \"name\": name,\n",
    "            \"finish_time\": finish_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add a little jitter to be less boring\n",
    "    excitement = np.ones_like(x_pos) * 0.01\n",
    "    excitement[: len(excitement) // 2] *= -1\n",
    "    np.random.shuffle(excitement)\n",
    "    race_df[\"x\"] += excitement\n",
    "    race_df.loc[0, \"x\"] = 0\n",
    "\n",
    "    return race_df\n",
    "\n",
    "\n",
    "def _gen_race_data(players, colors=px.colors.qualitative.T10):\n",
    "    \"\"\"'Simulate' a marble race between players\"\"\"\n",
    "    race_dfs = []\n",
    "    name_colors = zip(players, colors)\n",
    "    for i, (name, color) in enumerate(name_colors):\n",
    "        race_df = _gen_player_data(color, name, i * 0.1)\n",
    "        race_dfs.append(race_df)\n",
    "\n",
    "    return pd.concat(race_dfs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def marble_race(players, seed=None):\n",
    "    \"\"\"'Simulate' a marble race\"\"\"\n",
    "    if isinstance(seed, int):\n",
    "        np.random.seed(seed)\n",
    "    race_df = _gen_race_data(players)\n",
    "\n",
    "    return (\n",
    "        race_df[[\"color\", \"name\", \"finish_time\"]]\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_marble_race(players, seed=None):\n",
    "    \"\"\"'Simulate' and plot a marble race\"\"\"\n",
    "    if isinstance(seed, int):\n",
    "        np.random.seed(seed)\n",
    "    race_df = _gen_race_data(players)\n",
    "\n",
    "    color_df = race_df[[\"color\", \"name\"]].drop_duplicates()\n",
    "    color_discrete_map = {}\n",
    "    for _, row in color_df.iterrows():\n",
    "        color_discrete_map[row[\"name\"]] = row[\"color\"]\n",
    "\n",
    "    fig = px.scatter(\n",
    "        data_frame=race_df,\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        color=\"name\",\n",
    "        text=\"name\",\n",
    "        animation_frame=\"time\",\n",
    "        title=\"Thinkful Marble Racing Series\",\n",
    "        color_discrete_map=color_discrete_map,\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker={\"size\": 20})\n",
    "    fig.update_layout(showlegend=False)\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=[1, 1], y=[-300, 300], mode=\"lines\", line={\"color\": \"black\"},)\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        {\"range\": [-0.1, 1.1], \"showgrid\": False, \"zeroline\": False, \"visible\": False,}\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        {\"range\": [-0.1, 1.1], \"showgrid\": False, \"zeroline\": False, \"visible\": False,}\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Off to the races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "racers = [\n",
    "    \"Adam\",\n",
    "    \"Anthony\",\n",
    "    \"Dillan\",\n",
    "    \"Gaukhar\",\n",
    "    \"Harinder\",\n",
    "    \"James\",\n",
    "    \"Joshua\",\n",
    "    \"Leon\",\n",
    "    \"Mason\",\n",
    "    \"Rachel\",\n",
    "    \"Steve\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Claim: Blue marbles are faster than other marbles.**\n",
    "\n",
    "* Do you believe me that blue marbles are faster? why? why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_marble_race(racers, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = marble_race(racers, 90)\n",
    "results.sort_values(\"finish_time\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do you believe me now that blue marbles are faster? why? why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_marble_race(racers, 1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = marble_race(racers, 1337)\n",
    "results.sort_values(\"finish_time\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do you believe me now that blue marbles are faster? why? why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_marble_race(racers, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = marble_race(racers, 42)\n",
    "results.sort_values(\"finish_time\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you believe me now that blue marbles are faster? why? why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_marble_race(racers, 8675309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = marble_race(racers, 8675309)\n",
    "results.sort_values(\"finish_time\").head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you believe me now that blue marbles are faster? why? why not?\n",
    "\n",
    "What would it take for me to convince you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, we can think of a t-test (and many statistical tests) as a ratio of signal to noise:\n",
    "\n",
    "**Intuition only $t$ formula:**\n",
    "\n",
    "$$t = \\frac{signal}{noise}$$\n",
    "\n",
    "\n",
    "* If we keep $noise$ the same and the $signal$ gets larger, what happens to the value of $t$?  Does $t$ get larger or smaller as the $signal$ gets large?\n",
    "* If we keep $signal$ the same and the $noise$ gets larger, what happens to the value of $t$?  Does $t$ get larger or smaller as the $noise$ gets large?\n",
    "\n",
    "\n",
    "### Signal\n",
    "\n",
    "The signal is the thing we are actually trying to measure.  Intuitively, the signal of a t-test is trying to measure is: \"is there a difference of means between two groups?\". Mathematically, this signal is: $\\overline{x}_{1}-\\overline{x}_{2}$ (difference of means between the two groups)\"\n",
    "\n",
    "**Updated $t$ formula:**\n",
    "\n",
    "* $\\overline{x}$ = sample mean\n",
    "\n",
    "$$t = \\frac{\\overline{x}_{1}-\\overline{x}_{2}}{noise}$$\n",
    "\n",
    "If the 2 group means are identical, what is the value of $t$?\n",
    "\n",
    "### Noise\n",
    "\n",
    "The noise is trying to quantify the quality and consistency of our evidence.  Do we have a lot of evidence (i.e. do we have a large sample size)?  Is this evidence consistent or are the numbers all over the place (i.e. do we have high variance)?\n",
    "\n",
    "A little more advanced intuition, if you're familiar with the metric '[standard error](https://www.statisticshowto.com/what-is-the-standard-error-of-a-sample/)', the noise of a t-test follows the same idea, but accounting for both of our groups at once.\n",
    "\n",
    "**Updated $t$ formula:**\n",
    "\n",
    "\n",
    "* $n$ = sample size (how much evidence?)\n",
    "* $s$ = sample standard deviation (how consistent?)\n",
    "\n",
    "$$t = \\frac{signal}{noise}$$\n",
    "\n",
    "$$t = \\frac{\\overline{x}_{1}-\\overline{x}_{2}}{\\sqrt{\\frac{s_{1}^{2}}{n_{1}}+\\frac{s_{2}^{2}}{n_{2}}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate this formula to python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# test data (expected output of calculating t is about -169)\n",
    "x1 = np.random.normal(10, 0.1, 50)\n",
    "x2 = np.random.normal(13, 0.1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = ____ - ____\n",
    "noise = np.sqrt(____ / ____ + ____ / ____)\n",
    "t = signal / noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p-values & hypotheses\n",
    "\n",
    "If the 2 group means are identical, we have a $t$ value of 0.  As the distance between the 2 means increases, so does the value of $t$.  At what point do we declare signifcance?  This is where a the famous \"p value\" comes in.  A p-value measures how likely is this value of $t$, assuming there's no difference in means.\n",
    "\n",
    "Remember in our marble race, we said it should be up to the person claiming blue is faster to be the one needing proof.  Our default is position is the status quo.  \n",
    "\n",
    "In court, people are innocent until proven guilty.  In a t-test, the 2 means are the same until proven different; this means our default position is that the 2 means are equal.  The way this is represented in statistical testing is through 'null' and 'alternative' hypotheses.  The null hypothesis is the default position (the means are equal) the alternative hypothesis is challenging the default position (the means are different).  Formally you migh see these written like below.\n",
    "\n",
    "* $H_o$: There is no difference of means; $\\overline{x}_1 - \\overline{x}_2 = 0$\n",
    "* $H_a$: There is a difference of means; $\\overline{x}_1 - \\overline{x}_2 \\neq 0$\n",
    "\n",
    "Our p value is telling us \"whats the probability we'd observe this difference of means assuming that there's no difference?\" or \"whats the probability we'd observe this assuming our null hypothesis?\".  \n",
    "\n",
    "Whats the probability that the blue marble wins a single race given there's no difference in speed based on marble color?  There's a pretty good chance (i.e. a high **p**robability blue can win 1 w/o a true speed diff), so we indicate this with a large p value.\n",
    "\n",
    "Whats the probability that the blue marble wins a 10 out of 20 races given there's no difference in speed based on marble color?  There's still a chance that this happens, but the **p**robility of there not being a difference is lowering, so we indicate this with a lower p value.\n",
    "\n",
    "Whats the probability that the blue marble wins a 20 out of 20 races given there's no difference in speed based on marble color?  There's a small chance that this happens, but the **p**robility of there not being a difference is starting to be very small, so we indicate this with a low p value.\n",
    "\n",
    "* Step 1: Assume there's no difference.\n",
    "* Step 2: Collect data.\n",
    "* Step 3: Whats the probability we see this data given our assumption of no difference?\n",
    "* Step 4: Compare this probability to our threshold of being convinced of a difference (commonly 5%, but this can be changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing t-tests in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enough with your discussion and intuition! Tell me the steps as directly as possible.**\n",
    "\n",
    "* Separate your data into the 2 groups of interest\n",
    "* Check that the data is normal enough\n",
    "* Input the data into `stats.ttest_ind()` and out comes a value of $t$ and a $p$-value\n",
    "* Compare the $p$-value to 5%\n",
    "  * Is the $p$-value less than 5%? Significant difference of means\n",
    "  * Is the $p$-value greater than 5%? No significant difference of means\n",
    "\n",
    "----\n",
    "\n",
    "Let's do this for our marbles.\n",
    "\n",
    "* Use the `marble_race` function to run 100 races and combine these dataframes into 1 big dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dfs = []\n",
    "for i in ____:\n",
    "    race_df = marble_race(racers)\n",
    "    race_dfs.____(____)\n",
    "\n",
    "marble_data = pd.____(race_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a column in the dataframe that indicates what group the marble belongs to (i.e. blue vs not blue)\n",
    "* Create a boxplot or violinplot that compares these 2 groups\n",
    "* What are your thoughts at this point? expect a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_blue = \"#4C78A8\"\n",
    "\n",
    "marble_data['is_blue'] = _____\n",
    "\n",
    "sns._____(____, ____, data=marble_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separate the data into 2 dataframes: `blue` & `not_blue`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = ____\n",
    "not_blue = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Are the 2 groups normal enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform the t-test.  Is there a significant difference? Do we reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If there is a significant difference, how big is it?\n",
    "\n",
    "...to be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
